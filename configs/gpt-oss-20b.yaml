# Configuration for Llama 2 70B model with tensor parallelism
# Large model requiring both GPUs
# NOTE: Requires access to gated repository

model:
  name: "openai/gpt-oss-20b"
  trust_remote_code: true

inference:
  tensor_parallel_size: 2
  gpu_memory_utilization: 0.8
  max_model_len: 4096
  dtype: bfloat16

server:
  host: "0.0.0.0"
  port: 8000

generation_defaults:
  temperature: 0.7
  max_tokens: 512