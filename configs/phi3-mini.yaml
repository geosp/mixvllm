# Configuration for Phi-3 Mini model
# Lightweight model, fits on single GPU

model:
  name: "microsoft/Phi-3-mini-4k-instruct"

inference:
  tensor_parallel_size: 1
  gpu_memory_utilization: 0.8
  max_model_len: 4096

server:
  host: "0.0.0.0"
  port: 8000

generation_defaults:
  temperature: 0.7
  max_tokens: 512